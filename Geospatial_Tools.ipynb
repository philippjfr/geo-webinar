{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python Geospatial Tools Webinar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Foundational tools\n",
    "\n",
    "The geospatial ecosystem in Python builds on a number of foundational tools much like the rest of the Python scientific ecosystem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numpy\n",
    "\n",
    "NumPy is the fundamental package for scientific computing in Python. It is a Python library that provides a multidimensional array object, various derived objects (such as masked arrays and matrices), and an assortment of routines for fast operations on arrays, including mathematical, logical, shape manipulation, sorting, selecting, I/O, discrete Fourier transforms, basic linear algebra, basic statistical operations, random simulation and much more.\n",
    "\n",
    "- [Documentation](https://numpy.org/doc/stable/index.html)\n",
    "- [GitHub](https://github.com/numpy/numpy)\n",
    "\n",
    "Installation:\n",
    "\n",
    "```\n",
    "conda install numpy\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "a = np.array([1, 2, 3])\n",
    "\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pandas\n",
    "\n",
    "pandas is an open source, BSD-licensed library providing high-performance, easy-to-use data structures and data analysis tools for the Python programming language.\n",
    "\n",
    "- [Documentation](https://pandas.pydata.org/docs/)\n",
    "- [GitHub](https://github.com/pandas-dev/pandas)\n",
    "\n",
    "Installation:\n",
    "\n",
    "```\n",
    "conda install pandas\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    {\n",
    "        \"Name\": [\n",
    "            \"Braund, Mr. Owen Harris\",\n",
    "            \"Allen, Mr. William Henry\",\n",
    "            \"Bonnell, Miss. Elizabeth\",\n",
    "        ],\n",
    "        \"Age\": [22, 35, 58],\n",
    "        \"Sex\": [\"male\", \"male\", \"female\"],\n",
    "    }\n",
    ")\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dask\n",
    "\n",
    "Dask is a flexible library for parallel computing in Python.\n",
    "\n",
    "- [Documentation](https://docs.dask.org/en/latest/)\n",
    "- [GitHub](https://github.com/pandas-dev/pandas)\n",
    "\n",
    "Installation:\n",
    "\n",
    "```\n",
    "conda install dask\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### dask.distributed\n",
    "\n",
    "Starting the Dask Client is optional. It will provide a dashboard which is useful to gain insight on the computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import Client, progress\n",
    "\n",
    "client = Client(processes=False, threads_per_worker=4,\n",
    "                n_workers=1, memory_limit='16GB')\n",
    "\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### dask.array\n",
    "\n",
    "Dask arrays coordinate many Numpy arrays, arranged into chunks within a grid. They support a large subset of the Numpy API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.array as da\n",
    "\n",
    "x = da.random.random((10000, 10000), chunks=(1000, 1000))\n",
    "\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summed = x.sum(axis=0)\n",
    "\n",
    "summed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summed.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### dask.dataframe\n",
    "\n",
    "Dask Dataframes coordinate many Pandas dataframes, partitioned along an index. They support a large subset of the Pandas API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask\n",
    "\n",
    "import dask.dataframe as dd\n",
    "\n",
    "ddf = dask.datasets.timeseries()\n",
    "\n",
    "ddf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf2 = ddf[ddf.y > 0]\n",
    "\n",
    "ddf3 = ddf2.groupby('name').x.std()\n",
    "\n",
    "ddf3.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numba\n",
    "\n",
    "Numba translates Python functions to optimized machine code at runtime using the industry-standard LLVM compiler library. Numba-compiled numerical algorithms in Python can approach the speeds of C or FORTRAN.\n",
    "\n",
    "- [Documentation](https://numba.pydata.org/)\n",
    "- [GitHub](https://github.com/numba/numba)\n",
    "\n",
    "Installation:\n",
    "\n",
    "```\n",
    "conda install numba\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import jit\n",
    "\n",
    "x = np.arange(100).reshape(10, 10)\n",
    "\n",
    "@jit(nopython=True) # Set \"nopython\" mode for best performance, equivalent to @njit\n",
    "def go_fast(a): # Function is compiled to machine code when called the first time\n",
    "    trace = 0.0\n",
    "    for i in range(a.shape[0]):   # Numba likes loops\n",
    "        trace += np.tanh(a[i, i]) # Numba likes NumPy functions\n",
    "    return a + trace              # Numba likes NumPy broadcasting\n",
    "\n",
    "print(go_fast(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cupy\n",
    "\n",
    "CuPy is an implementation of NumPy-compatible multi-dimensional array on CUDA. CuPy consists of cupy.ndarray, the core multi-dimensional array class, and many functions on it. It supports a subset of numpy.ndarray interface.\n",
    "\n",
    "- [Documentation](https://docs.cupy.dev/en/stable/)\n",
    "- [GitHub](https://github.com/cupy/cupy)\n",
    "\n",
    "Installation:\n",
    "\n",
    "```\n",
    "conda install -c conda-forge cupy\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cupy as cp\n",
    "\n",
    "x = cp.arange(6).reshape(2, 3).astype('f')\n",
    "\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.sum(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vector Data\n",
    "\n",
    "<img src=\"vector_data2.png\"></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Geopandas\n",
    "\n",
    "GeoPandas is an open source project to make working with geospatial data in python easier. GeoPandas extends the datatypes used by pandas to allow spatial operations on geometric types. Geometric operations are performed by shapely. Geopandas further depends on fiona for file access and matplotlib for plotting.\n",
    "\n",
    "- [Documentation](https://geopandas.org/docs.html)\n",
    "- [GitHub](https://github.com/geopandas/geopandas)\n",
    "\n",
    "Installation:\n",
    "\n",
    "```\n",
    "conda install -c conda-forge geopandas\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "\n",
    "url = \"http://d2ad6b4ur7yvpq.cloudfront.net/naturalearth-3.3.0/ne_110m_land.geojson\"\n",
    "gdf = gpd.read_file(url)\n",
    "\n",
    "gdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indexing the geometry column returns `shapely` objects:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf.geometry.iloc[21]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However underlying this is a `GeometryArray` class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(gdf.geometry.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "which stores pointers to GEOS objects:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf.geometry.values.data[:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### spatialpandas\n",
    "\n",
    "Spatialpandas provides Pandas and Dask extensions for vectorized spatial and geometric operations, such as fast, spatially indexed rendering of large collections of polygons, lines, or points.\n",
    "\n",
    "- [Documentation](https://nbviewer.jupyter.org/github/holoviz/spatialpandas/blob/master/examples/Overview.ipynb)\n",
    "- [GitHub](https://github.com/holoviz/spatialpandas)\n",
    "\n",
    "Installation:\n",
    "\n",
    "```\n",
    "conda install -c holoviz spatialpandas\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "spatialpandas does not provide any file access or I/O support for classic geospatial formats but does allow storing geometry data in parquet files. It also transparently converts Geopandas objects:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spatialpandas as spd\n",
    "\n",
    "sdf = spd.GeoDataFrame(gdf)\n",
    "\n",
    "sdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of storing shapely or GEOS objects, spatialpandas declares geometry array classes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(sdf.geometry.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "which stores the geometry data as a contiguous PyArrow `ListArray`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf.geometry.values.data[:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Spatial indexing\n",
    "\n",
    "Spatialpandas supports spatially indexing a GeoDataFrame of geometries ensuring that nearby geometries are stored in the same partitions. This ensures that without loading data in memory we can quickly look up specific geometries with a spatial query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sidf = dd.from_pandas(sdf, npartitions=8)\n",
    "\n",
    "sidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datashader as ds\n",
    "\n",
    "def plot_partitions(ddf):\n",
    "    # Get divisions array\n",
    "    divs = np.array(ddf.divisions)[:-1]\n",
    "    \n",
    "    # Add categorical \"partition\" column\n",
    "    ddf2 = ddf.map_partitions(\n",
    "        lambda df: df.assign(\n",
    "            partition=pd.Categorical(np.searchsorted(divs, df.index, side=\"right\"))\n",
    "        )\n",
    "    ).compute()\n",
    "    \n",
    "    # Create Datashader image, coloring countries by partition\n",
    "    cvs = ds.Canvas(plot_width=650, plot_height=400)\n",
    "    agg = cvs.polygons(ddf2, geometry='geometry', agg=ds.count_cat('partition'))\n",
    "    return ds.transfer_functions.shade(agg)\n",
    "\n",
    "plot_partitions(sidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sidf.cx[-80:-85]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Spatial Joins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minx, miny, maxx, maxy = sidf.geometry.total_bounds\n",
    "\n",
    "N = 1_000_000\n",
    "\n",
    "df_points = gpd.GeoDataFrame(\n",
    "    {\"id\": np.arange(N)},\n",
    "    geometry=gpd.points_from_xy(minx + maxx * np.random.random(N), miny + maxy * np.random.random(N)),\n",
    "    crs=gdf.crs\n",
    ")\n",
    "\n",
    "sdf_points = dd.from_pandas(spd.GeoDataFrame(df_points), npartitions=16).persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "spd.sjoin(sdf_points, sdf).compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dask-geopandas\n",
    "\n",
    "Parallel GeoPandas with Dask supporting some of the same features as the DaskGeoDataFrame such as spatial indexing and spatial joins.\n",
    "\n",
    "- [Documentation](https://nbviewer.jupyter.org/github/holoviz/spatialpandas/blob/master/examples/Overview.ipynb)\n",
    "- [GitHub](https://github.com/geopandas/dask-geopandas/)\n",
    "\n",
    "Installation:\n",
    "\n",
    "```\n",
    "pip install dask-geopandas\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask_geopandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf = dask_geopandas.from_geopandas(df_points, npartitions=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "dask_geopandas.sjoin(ddf, gdf).compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cuspatial\n",
    "\n",
    "- [Documentation](https://intake.readthedocs.io/en/latest/)\n",
    "- [GitHub](https://github.com/rapidsai/cuspatial)\n",
    "\n",
    "Installation:\n",
    "\n",
    "```\n",
    "conda install -c conda-forge -c rapidsai-nightly cuspatial\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Raster data\n",
    "\n",
    "To represent and work with raster data in Python there are a number of essential tools which in turn build on some or all of the foundational tools above.\n",
    "\n",
    "<img src=\"gridded_types.png\"></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### xarray\n",
    "\n",
    "Xarray is an open source project and Python package that provides a toolkit for working with labeled multi-dimensional arrays of data. Xarray adopts the Common Data Model for self-describing scientific data in widespread use in the Earth sciences: `xarray.Dataset` is an in-memory representation of a netCDF file. Xarray provides the basic data structures, as well as powerful tools for computation and visualization.\n",
    "\n",
    "- [Documentation](https://xarray.pydata.org/en/stable/)\n",
    "- [GitHub](https://github.com/pydata/xarray)\n",
    "\n",
    "Installation:\n",
    "\n",
    "```\n",
    "conda install xarray\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "\n",
    "air_temp = xr.tutorial.open_dataset('air_temperature')\n",
    "\n",
    "air_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "air_temp.sel({'lat': slice(75, 50), 'lon': slice(200, 220)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datashader\n",
    "\n",
    "*Accurately render even the largest data*\n",
    "\n",
    "Datashader is a graphics pipeline system for creating meaningful representations of large datasets quickly and flexibly. Datashader breaks the creation of images into a series of explicit steps that allow computations to be done on intermediate representations. This approach allows accurate and effective visualizations to be produced automatically without trial-and-error parameter tuning, and also makes it simple for data scientists to focus on particular data and relationships of interest in a principled way.\n",
    "\n",
    "The computation-intensive steps in this process are written in ordinary Python but transparently compiled to machine code using Numba and flexibly distributed across CPU cores and processors using Dask or GPUs using CUDA. This approach provides a highly optimized rendering pipeline that makes it practical to work with extremely large datasets even on standard hardware, while exploiting distributed and GPU systems when available.\n",
    "\n",
    "- [Documentation](https://datashader.org/)\n",
    "- [GitHub](https://github.com/holoviz/datashader)\n",
    "\n",
    "Installation:\n",
    "\n",
    "```\n",
    "conda install datashader\n",
    "```\n",
    "\n",
    "<style type=\"text/css\">.arbit .trary a { color: inherit; }.arbit .trary\n",
    ".sL{text-align:center;padding:2px 2px 2px 2px;background-color:#ffffff;font-weight:bold;width:60px}.arbit .trary\n",
    ".sG{text-align:center;padding:2px 2px 2px 2px;background-color:#ffffff;font-weight:bold;font-family:monospace}.arbit .trary\n",
    ".sY{text-align:center;padding:2px 2px 2px 2px;background-color:#b7e1cd;}.arbit .trary \n",
    ".sN{text-align:center;padding:2px 2px 2px 2px;background-color:#f4c7c3;}.arbit .trary\n",
    ".sM{text-align:center;padding:2px 2px 2px 2px;background-color:#fce8b2;}.arbit .trary\n",
    "</style>\n",
    "<div class=\"arbit\">\n",
    "<table class=\"trary\" cellspacing=\"0\" cellpadding=\"0\">\n",
    "<thead>\n",
    "<tr>\n",
    "  <th class=\"sG\">Data object</th>\n",
    "  <th class=\"sG\">Structure</th>\n",
    "  <th class=\"sG\">Compute</th>\n",
    "  <th class=\"sG\">Memory</th>\n",
    "  <th class=\"sG\">Description</th>\n",
    "  <th class=\"sG\">points</th>\n",
    "  <th class=\"sG\">line</th>\n",
    "  <th class=\"sG\">area</th>\n",
    "  <th class=\"sG\">trimesh</th>\n",
    "  <th class=\"sG\">raster</th>\n",
    "  <th class=\"sG\">quadmesh</th>\n",
    "  <th class=\"sG\">polygons</th>\n",
    "</tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "<tr>\n",
    "  <td class=\"sL\"><a href=\"https://pandas.pydata.org\">Pandas DF</a></td>\n",
    "  <td>columnar</td>\n",
    "  <td>1-core CPU</td>\n",
    "  <td>in-core</td>\n",
    "  <td>Standard dataframes</td>\n",
    "  <td class=\"sY\">Yes</td>\n",
    "  <td class=\"sY\">Yes</td>\n",
    "  <td class=\"sY\">Yes</td>\n",
    "  <td class=\"sY\">Yes</td>\n",
    "  <td class=\"sM\">-</td>\n",
    "  <td class=\"sM\">-</td>\n",
    "  <td class=\"sM\">-</td>\n",
    "</tr>\n",
    "<tr>\n",
    "  <td class=\"sL\"><a href=\"https://dask.org\">DaskDF + PandasDF</a></td>\n",
    "  <td>columnar</td>\n",
    "  <td>distributed CPU</td>\n",
    "  <td>out-of-core</td>\n",
    "  <td>Distributed DataFrames</td>\n",
    "  <td class=\"sY\">Yes</td>\n",
    "  <td class=\"sY\">Yes</td>\n",
    "  <td class=\"sY\">Yes</td>\n",
    "  <td class=\"sY\">Yes</td>\n",
    "  <td class=\"sM\">-</td>\n",
    "  <td class=\"sM\">-</td>\n",
    "  <td class=\"sM\">-</td>\n",
    "</tr>\n",
    "<tr>\n",
    "  <td class=\"sL\"><a href=\"https://github.com/rapidsai/cudf\">cuDF</a></td>\n",
    "  <td>columnar</td>\n",
    "  <td>single GPU</td>\n",
    "  <td>in-core</td>\n",
    "  <td>NVIDIA GPU DataFrames</td>\n",
    "  <td class=\"sY\">Yes</td>\n",
    "  <td class=\"sY\">Yes</td>\n",
    "  <td class=\"sY\">Yes</td>\n",
    "  <td class=\"sN\">No</td>\n",
    "  <td class=\"sM\">-</td>\n",
    "  <td class=\"sM\">-</td>\n",
    "  <td class=\"sM\">-</td>\n",
    "</tr>\n",
    "<tr>\n",
    "  <td class=\"sL\"><a href=\"https://docs.rapids.ai/api/cudf/stable/10min.html\">DaskDF + cuDF</a></td>\n",
    "  <td>columnar</td>\n",
    "  <td>distributed GPU</td>\n",
    "  <td>out-of-core</td>\n",
    "  <td>Distributed NVIDIA GPUs</td>\n",
    "  <td class=\"sY\">Yes</td>\n",
    "  <td class=\"sY\">Yes</td>\n",
    "  <td class=\"sY\">Yes</td>\n",
    "  <td class=\"sN\">No</td>\n",
    "  <td class=\"sM\">-</td>\n",
    "  <td class=\"sM\">-</td>\n",
    "  <td class=\"sM\">-</td>\n",
    "</tr>\n",
    "<tr>\n",
    "  <td class=\"sL\"><a href=\"https://github.com/holoviz/spatialpandas\">SpatialPandasDF</a></td>\n",
    "  <td>ragged</td>\n",
    "  <td>1-core CPU</td>\n",
    "  <td>in-core</td>\n",
    "  <td>Ragged + spatial indexing</td>\n",
    "  <td class=\"sY\">Yes</td>\n",
    "  <td class=\"sY\">Yes</td>\n",
    "  <td class=\"sM\">-</td>\n",
    "  <td class=\"sM\">-</td>\n",
    "  <td class=\"sM\">-</td>\n",
    "  <td class=\"sM\">-</td>\n",
    "  <td class=\"sY\">Yes</td>\n",
    "</tr>\n",
    "<tr>\n",
    "  <td class=\"sL\"><a href=\"https://github.com/holoviz/spatialpandas\">Dask + SpatialPandasDF</a></td>\n",
    "  <td>ragged</td>\n",
    "  <td>distributed CPU</td>\n",
    "  <td>out-of-core</td>\n",
    "  <td>Distributed ragged arrays</td>\n",
    "  <td class=\"sY\">Yes</td>\n",
    "  <td class=\"sY\">Yes</td>\n",
    "  <td class=\"sM\">-</td>\n",
    "  <td class=\"sM\">-</td>\n",
    "  <td class=\"sM\">-</td>\n",
    "  <td class=\"sM\">-</td>\n",
    "  <td class=\"sY\">Yes</td>\n",
    "</tr>\n",
    "<tr>\n",
    "  <td class=\"sL\"><a href=\"http://xarray.pydata.org\">Xarray + NumPy</a></td>\n",
    "  <td>n-D</td>\n",
    "  <td>1-core CPU</td>\n",
    "  <td>in-core</td>\n",
    "  <td>n-D CPU arrays</td>\n",
    "  <td class=\"sN\">No</td>\n",
    "  <td class=\"sN\">No</td>\n",
    "  <td class=\"sN\">No</td>\n",
    "  <td class=\"sN\">No</td>\n",
    "  <td class=\"sY\">Yes</td>\n",
    "  <td class=\"sY\">Yes</td>\n",
    "  <td class=\"sM\">-</td>\n",
    "</tr>\n",
    "<tr>\n",
    "  <td class=\"sL\"><a href=\"(https://dask.org\">Xarray+DaskArray</a></td>\n",
    "  <td>n-D</td>\n",
    "  <td>distributed CPU</td>\n",
    "  <td>out-of-core</td>\n",
    "  <td>Distributed n-D arrays</td>\n",
    "  <td class=\"sN\">No</td>\n",
    "  <td class=\"sN\">No</td>\n",
    "  <td class=\"sN\">No</td>\n",
    "  <td class=\"sN\">No</td>\n",
    "  <td class=\"sY\">Yes</td>\n",
    "  <td class=\"sY\">Yes</td>\n",
    "  <td class=\"sM\">-</td>\n",
    "</tr>\n",
    "<tr>\n",
    "  <td class=\"sL\"><a href=\"https://cupy.chainer.org\">Xarray+CuPy</a></td>\n",
    "  <td>n-D</td>\n",
    "  <td>single GPU</td>\n",
    "  <td>in-core</td>\n",
    "  <td>Single-GPU n-D arrays</td>\n",
    "  <td class=\"sN\">No</td>\n",
    "  <td class=\"sN\">No</td>\n",
    "  <td class=\"sN\">No</td>\n",
    "  <td class=\"sN\">No</td>\n",
    "  <td class=\"sN\">No</td>\n",
    "  <td class=\"sY\">Yes</td>\n",
    "  <td class=\"sM\">-</td>\n",
    "</tr>\n",
    "</tbody></table></div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datashader as ds\n",
    "\n",
    "W = 1280\n",
    "H = 768"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "points_df = dd.read_parquet('/Users/philippjfr/development/datashader/examples/data/nyc_taxi.parq/').compute()\n",
    "\n",
    "points_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "cvs = ds.Canvas(plot_width=W, plot_height=H)\n",
    "\n",
    "pickup_agg = cvs.points(points_df, 'pickup_x', 'pickup_y')\n",
    "\n",
    "pickup_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.tf.shade(pickup_agg, how='log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "streets_df = spd.GeoDataFrame(gpd.read_file('./streets.json'))\n",
    "\n",
    "streets_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "cvs = ds.Canvas(plot_width=850, plot_height=500)\n",
    "\n",
    "street_agg = cvs.line(streets_df, geometry='geometry')\n",
    "\n",
    "street_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.tf.shade(street_agg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Polygons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_df = spd.GeoDataFrame(pd.read_parquet('./nyc_buildings.parq/'))\n",
    "\n",
    "poly_df['type'] = poly_df['type'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(poly_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "cvs = ds.Canvas(plot_width=W, plot_height=H)\n",
    "\n",
    "poly_agg = cvs.polygons(poly_df, geometry='geometry', agg=ds.reductions.count_cat('type'))\n",
    "\n",
    "poly_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import colorcet\n",
    "\n",
    "ds.tf.shade(poly_agg, color_key=colorcet.glasbey)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## xarray-spatial\n",
    "\n",
    "Xarray-Spatial implements common raster analysis functions using Numba and provides an easy-to-install, easy-to-extend codebase for raster analysis.\n",
    "\n",
    "xarray-spatial does not depend on GDAL / GEOS, which makes it fully extensible in Python but does limit the breadth of operations that can be covered. xarray-spatial is meant to include the core raster-analysis functions needed for GIS developers / analysts, implemented independently of the non-Python geo stack.\n",
    "\n",
    "- [Documentation](https://xarray-spatial.org/)\n",
    "- [GitHub](https://github.com/makepath/xarray-spatial)\n",
    "\n",
    "Installation:\n",
    "\n",
    "```\n",
    "conda install -c conda-forge xarray-spatial\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xrspatial import generate_terrain\n",
    "\n",
    "W = 800\n",
    "H = 600\n",
    "\n",
    "cvs = ds.Canvas(plot_width=W, plot_height=H, x_range=(-20e6, 20e6), y_range=(-20e6, 20e6))\n",
    "\n",
    "terrain = generate_terrain(canvas=cvs)\n",
    "\n",
    "ds.tf.shade(terrain, cmap=['black', 'white'], how='linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xrspatial import hillshade\n",
    "from xrspatial import quantile\n",
    "\n",
    "qcut_agg = quantile(terrain, k=15)\n",
    "\n",
    "ds.tf.stack(\n",
    "    ds.tf.shade(hillshade(qcut_agg), cmap=['gray', 'white'], alpha=255, how='linear'),\n",
    "    ds.tf.shade(qcut_agg,     cmap=ds.colors.Elevation,      alpha=128, how='linear')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_common = list(poly_df.type.value_counts().sort_values().iloc[-50:].index)\n",
    "\n",
    "filtered_polys = poly_df[poly_df.type.isin(most_common)].copy()\n",
    "\n",
    "filtered_polys['zones'] = [most_common.index(t) for t in filtered_polys.type]\n",
    "\n",
    "cvs = ds.Canvas(\n",
    "    plot_width=5000, plot_height=5000,\n",
    "    x_range=(pickup_agg.pickup_x.min().item(), pickup_agg.pickup_x.max().item()),\n",
    "    y_range=(pickup_agg.pickup_y.min().item(), pickup_agg.pickup_y.max().item())\n",
    ")\n",
    "\n",
    "zones_agg = cvs.polygons(filtered_polys, geometry='geometry', agg=ds.reductions.min('zones'))\n",
    "\n",
    "pickup_agg = cvs.points(points_df, 'pickup_x', 'pickup_y', agg=ds.sum('passenger_count'))\n",
    "dropoff_agg = cvs.points(points_df, 'dropoff_x', 'dropoff_y', agg=ds.sum('passenger_count'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import colorcet as cc\n",
    "\n",
    "ds.tf.stack(\n",
    "    ds.tf.shade(zones_agg, cmap=cc.glasbey),\n",
    "    ds.tf.shade(pickup_agg, cmap=['white', 'red'])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xrspatial import zonal_stats\n",
    "\n",
    "custom_stats = dict(passenger_pickups=np.sum)\n",
    "\n",
    "pickup_stats = zonal_stats(zones_agg, pickup_agg, zone_ids=list(range(50)), stats_funcs=custom_stats)\n",
    "pickup_stats.insert(0, 'Type', [most_common[z] for z in pickup_stats.zone])\n",
    "pickup_stats.sort_values('passenger_pickups', ascending=False).iloc[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_stats = dict(passenger_dropoffs=np.sum)\n",
    "\n",
    "dropoff_stats = zonal_stats(zones_agg, dropoff_agg, zone_ids=list(range(50)), stats_funcs=custom_stats)\n",
    "dropoff_stats.insert(0, 'Type', [most_common[z] for z in dropoff_stats.zone])\n",
    "dropoff_stats.sort_values('passenger_dropoffs', ascending=False).iloc[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data catalogs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intake\n",
    "\n",
    "Intake is a lightweight set of tools for loading and sharing data in data science projects.\n",
    "\n",
    "- [Documentation](https://intake.readthedocs.io/en/latest/)\n",
    "- [GitHub](https://github.com/intake/intake)\n",
    "\n",
    "Installation:\n",
    "\n",
    "```\n",
    "conda install intake\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example catalog:\n",
    "\n",
    "```yaml\n",
    "plugins:\n",
    "  source:\n",
    "    - module: intake_xarray\n",
    "sources:\n",
    "  esgf:\n",
    "    description: CREATE sample\n",
    "    driver: opendap\n",
    "    args:\n",
    "      urlpath: 'http://esgf.nccs.nasa.gov/thredds/dodsC/CREATE-IP/reanalysis/ECMWF/IFS-Cy31r2/day/atmos/pr/pr_day_reanalysis_IFS-Cy31r2_19790101-19791231.nc'\n",
    "      chunks: {}\n",
    "      xarray_kwargs:\n",
    "        decode_times: False\n",
    "        \n",
    "  geotiff:\n",
    "    description: Geotiff image of Landsat Surface Reflectance Level-2 Science Product L5.\n",
    "    driver: rasterio\n",
    "    cache:\n",
    "      - argkey: urlpath\n",
    "        regex: 'earth-data/landsat'\n",
    "        type: file\n",
    "    args:\n",
    "      urlpath: 's3://earth-data/landsat/small/LT05_L1TP_042033_{collection_date:%Y%m%d}_{processing_date:%Y%m%d}_01_T1_sr_band{band:1d}.tif'\n",
    "      chunks:\n",
    "        band: 1\n",
    "        x: 50\n",
    "        y: 50\n",
    "      concat_dim: band\n",
    "      storage_options: {'anon': True}\n",
    "    metadata:\n",
    "      plots:\n",
    "        band_image:\n",
    "          kind: 'image'\n",
    "          x: 'x'\n",
    "          y: 'y'\n",
    "          groupby: 'band'\n",
    "          rasterize: True\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import intake\n",
    "\n",
    "cat = intake.open_catalog('/Users/philippjfr/development/hvplot/examples/datasets.yaml')\n",
    "\n",
    "cat.us_crime.to_dask()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STAC\n",
    "\n",
    "\n",
    "- [Documentation](https://pystac.readthedocs.io/en/1.0/#)\n",
    "- [GitHub](https://github.com/stac-utils/pystac)\n",
    "\n",
    "Installation:\n",
    "\n",
    "```\n",
    "conda install intake\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matplotlib\n",
    "\n",
    "Matplotlib is a comprehensive library for creating static, animated, and interactive visualizations in Python.\n",
    "\n",
    "- [Documentation](https://matplotlib.org/stable/contents.html)\n",
    "- [GitHub](https://github.com/matplotlib/matplotlib)\n",
    "\n",
    "Installation:\n",
    "\n",
    "```\n",
    "conda install matplotlib\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Geopandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "gdf.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Xarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "air_temp.air.isel(time=0).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cartopy\n",
    "\n",
    "Cartopy is a Python package designed for geospatial data processing in order to produce maps and other geospatial data analyses.\n",
    "    \n",
    "- [Documentation](https://scitools.org.uk/cartopy/docs/latest/)\n",
    "- [GitHub](https://github.com/SciTools/cartopy)\n",
    "\n",
    "Installation:\n",
    "\n",
    "```\n",
    "conda install cartopy\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cartopy.crs as ccrs\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure(figsize=(10, 5))\n",
    "ax = fig.add_subplot(1, 1, 1, projection=ccrs.Mollweide())\n",
    "\n",
    "# make the map global rather than have it zoom in to\n",
    "# the extents of any plotted data\n",
    "ax.set_global()\n",
    "\n",
    "ax.stock_img()\n",
    "ax.coastlines()\n",
    "\n",
    "ax.plot(-0.08, 51.53, 'o', transform=ccrs.PlateCarree())\n",
    "ax.plot([-0.08, 132], [51.53, 43.17], transform=ccrs.PlateCarree())\n",
    "ax.plot([-0.08, 132], [51.53, 43.17], transform=ccrs.Geodetic())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### hvPlot\n",
    "\n",
    "hvPlot provides a high-level plotting API built on HoloViews that provides a general and consistent API for plotting data originating from Pandas, Dask DataFrames, cuDF, xarray, GeoPandas and Spatialpandas. hvPlot can integrate neatly with the individual libraries if an extension mechanism for the native plot APIs is offered, or it can be used as a standalone component.\n",
    "\n",
    "- [Documentation](https://hvplot.holoviz.org/)\n",
    "- [GitHub](https://github.com/holoviz/hvplot)\n",
    "\n",
    "Installation:\n",
    "\n",
    "```\n",
    "conda install hvplot\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hvplot.xarray\n",
    "import hvplot.pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Datashader integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "points_df.hvplot.points('pickup_x', 'pickup_y', rasterize=True, cnorm='log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import colorcet as cc\n",
    "\n",
    "poly_df.hvplot.polygons(datashade=True, aggregator=ds.count_cat('type'), color_key=cc.glasbey)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Geopandas support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf.hvplot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### xarray support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "air_temp.hvplot.image()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cartopy projection support via GeoViews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proj = ccrs.Orthographic(-90, 30)\n",
    "\n",
    "air_temp.air.hvplot.quadmesh(\n",
    "    'lon', 'lat', projection=proj, project=True, global_extent=True, \n",
    "    cmap='viridis', rasterize=True, coastline=True, frame_width=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ipyleaflet\n",
    "\n",
    "Interactive maps in the Jupyter notebook\n",
    "\n",
    "- [Documentation](https://ipyleaflet.readthedocs.io/en/latest/index.html)\n",
    "- [GitHub](https://github.com/jupyter-widgets/ipyleaflet)\n",
    "\n",
    "Installation:\n",
    "\n",
    "```\n",
    "conda install -c conda-forge ipyleaflet\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipyleaflet import Map, basemaps, basemap_to_tiles\n",
    "\n",
    "m = Map(\n",
    "    basemap=basemap_to_tiles(basemaps.NASAGIBS.ModisTerraTrueColorCR, \"2017-04-08\"),\n",
    "    center=(52.204793, 360.121558),\n",
    "    zoom=4\n",
    ")\n",
    "\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pydeck\n",
    "\n",
    "High-scale spatial rendering in Python, powered by deck.gl.\n",
    "\n",
    "- [Documentation](https://deckgl.readthedocs.io/en/latest/index.html)\n",
    "- [GitHub](https://github.com/visgl/deck.gl/tree/master/bindings/pydeck)\n",
    "\n",
    "Installation:\n",
    "\n",
    "```\n",
    "conda install -c conda-forge pydeck\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pydeck as pdk\n",
    "\n",
    "DATA_URL = \"https://raw.githubusercontent.com/visgl/deck.gl-data/master/examples/geojson/vancouver-blocks.json\"\n",
    "LAND_COVER = [[[-123.0, 49.196], [-123.0, 49.324], [-123.306, 49.324], [-123.306, 49.196]]]\n",
    "\n",
    "INITIAL_VIEW_STATE = pdk.ViewState(latitude=49.254, longitude=-123.13, zoom=11, max_zoom=16, pitch=45, bearing=0)\n",
    "\n",
    "polygon = pdk.Layer(\n",
    "    \"PolygonLayer\",\n",
    "    LAND_COVER,\n",
    "    stroked=False,\n",
    "    # processes the data as a flat longitude-latitude pair\n",
    "    get_polygon=\"-\",\n",
    "    get_fill_color=[0, 0, 0, 20],\n",
    ")\n",
    "\n",
    "geojson = pdk.Layer(\n",
    "    \"GeoJsonLayer\",\n",
    "    DATA_URL,\n",
    "    opacity=0.8,\n",
    "    stroked=False,\n",
    "    filled=True,\n",
    "    extruded=True,\n",
    "    wireframe=True,\n",
    "    get_elevation=\"properties.valuePerSqm / 20\",\n",
    "    get_fill_color=\"[255, 255, properties.growth * 255]\",\n",
    "    get_line_color=[255, 255, 255],\n",
    ")\n",
    "\n",
    "pdk.Deck(layers=[polygon, geojson], initial_view_state=INITIAL_VIEW_STATE)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
